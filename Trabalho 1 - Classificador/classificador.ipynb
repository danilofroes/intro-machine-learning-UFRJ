{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e1ed1f",
   "metadata": {},
   "source": [
    "## Trabalho 1 (Classificação) - Introdução ao Aprendizado de Máquina (EEL891)\n",
    "> Nome: Danilo Davi Gomes Fróes\n",
    ">\n",
    "> DRE: 124026825"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e99964",
   "metadata": {},
   "source": [
    "### Análise Exploratória de Dados (EDA - Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_treinamento = pd.read_csv('conjunto_de_treinamento.csv')\n",
    "\n",
    "print(f'Info: {df_treinamento.info()}')\n",
    "\n",
    "print(f'Descrição: {df_treinamento.describe()}')\n",
    "\n",
    "print(f'Targets: {df_treinamento['inadimplente'].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicao = pd.read_csv('conjunto_de_teste.csv')\n",
    "\n",
    "print(f'Info: {df_predicao.info()}')\n",
    "\n",
    "print(f'Descrição: {df_predicao.describe()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb72906",
   "metadata": {},
   "source": [
    "### **Tratamento dos Dados**\n",
    "Aqui é onde vai ser feito o tratamento dos dados após a análise geral. A ideia é deixar apenas dados que possuam valor de predição para o modelo, evitando vieses e análises desnecessárias.\n",
    "\n",
    "#### **Remoção de colunas**\n",
    "Algumas colunas foram vistas como problemáticas e serão removidas, elas são:\n",
    "- `id_solicitante`: Identificador único, não é necessário para o modelo.\n",
    "- `grau_instrucao`: Veio preenchida apenas com zeros.\n",
    "- `possui_telefone_celular`: Veio preenchida apenas com `'N'`.\n",
    "- `qtde_contas_bancarias_especiais`: Idêntica a outra coluna, `'qtde_contas_bancarias'`.\n",
    "\n",
    "#### **Substituição de valores nulos ocultos**\n",
    "Foi observado pelo dicionário de dados, que existem valores nulos que estão ocultos no dataframe, ou seja, não seriam enxergues como nulos no pré-processamento. Valores como `\"XX\"` e espaços em branco `\" \"` serão substituídos por valores nulos NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remover colunas que não são necessárias para o modelo\n",
    "colunas_a_remover = [\n",
    "    'id_solicitante',\n",
    "    'grau_instrucao',\n",
    "    'possui_telefone_celular',\n",
    "    'qtde_contas_bancarias_especiais'\n",
    "]\n",
    "df_treinamento = df_treinamento.drop(columns=colunas_a_remover, axis=1)\n",
    "\n",
    "# Substituir valores inválidos por NaN\n",
    "df_treinamento = df_treinamento.replace([' ', 'N/A', '', '?', 'XX', 'NULL'], np.nan)\n",
    "\n",
    "# Engenharia de Features\n",
    "df_treinamento['renda_total'] = df_treinamento['renda_mensal_regular'] + df_treinamento['renda_extra']\n",
    "df_treinamento['patrimonio_por_renda'] = df_treinamento['valor_patrimonio_pessoal'] / (df_treinamento['renda_total'] + 1)\n",
    "df_treinamento['renda_total_log'] = np.log1p(df_treinamento['renda_total'])\n",
    "df_treinamento['nasceu_onde_reside'] = (df_treinamento['estado_onde_nasceu'] == df_treinamento['estado_onde_reside']).astype(int)\n",
    "df_treinamento['reside_onde_trabalha'] = (df_treinamento['estado_onde_reside'] == df_treinamento['estado_onde_trabalha']).astype(int)\n",
    "colunas_cartoes = ['possui_cartao_visa', 'possui_cartao_mastercard', 'possui_cartao_diners', 'possui_cartao_amex', 'possui_outros_cartoes']\n",
    "df_treinamento['qtde_total_de_cartoes'] = df_treinamento[colunas_cartoes].sum(axis=1)\n",
    "\n",
    "# Tratamento de valores extremos\n",
    "df_treinamento.loc[df_treinamento['qtde_dependentes'] > 10, 'qtde_dependentes'] = 10\n",
    "df_treinamento.loc[df_treinamento['idade'] < 17, 'idade'] = df_treinamento['idade'].median()\n",
    "# df_treinamento.loc[df_treinamento['meses_no_trabalho'] < 1, 'meses_no_trabalho'] = df_treinamento['meses_no_trabalho'].median()\n",
    "\n",
    "colunas_redundantes = [\n",
    "    'renda_mensal_regular', \n",
    "    'renda_extra',\n",
    "    'renda_total',\n",
    "    'valor_patrimonio_pessoal'\n",
    "]\n",
    "\n",
    "df_treinamento = df_treinamento.drop(columns=colunas_redundantes, errors='ignore')\n",
    "\n",
    "# Tratamento de valores nulos\n",
    "cols_na_subs = ['profissao_companheiro', 'grau_instrucao_companheiro', 'codigo_area_telefone_residencial', 'codigo_area_telefone_trabalho', 'profissao', 'ocupacao']\n",
    "for col in cols_na_subs:\n",
    "    df_treinamento[col] = df_treinamento[col].fillna(-1)\n",
    "\n",
    "cols_cat_subs = ['estado_onde_trabalha', 'estado_onde_nasceu', 'tipo_residencia'] \n",
    "for col in cols_cat_subs:\n",
    "    moda = df_treinamento[col].mode()[0]\n",
    "    df_treinamento[col] = df_treinamento[col].fillna(moda)\n",
    "\n",
    "cols_num_subs = ['meses_na_residencia'] \n",
    "for col in cols_num_subs:\n",
    "    mediana = df_treinamento[col].median()\n",
    "    df_treinamento[col] = df_treinamento[col].fillna(mediana)\n",
    "\n",
    "df_treinamento['sexo'] = df_treinamento['sexo'].fillna('N')\n",
    "\n",
    "df_treinamento.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas que não são necessárias para o modelo\n",
    "colunas_a_remover = [\n",
    "    'id_solicitante',\n",
    "    'grau_instrucao',\n",
    "    'possui_telefone_celular',\n",
    "    'qtde_contas_bancarias_especiais'\n",
    "]\n",
    "df_predicao = df_predicao.drop(columns=colunas_a_remover, axis=1)\n",
    "\n",
    "# Substituir valores inválidos por NaN\n",
    "df_predicao = df_predicao.replace([' ', 'N/A', '', '?', 'XX', 'NULL'], np.nan)\n",
    "\n",
    "# Engenharia de Features\n",
    "df_predicao['renda_total'] = df_predicao['renda_mensal_regular'] + df_predicao['renda_extra']\n",
    "df_predicao['patrimonio_por_renda'] = df_predicao['valor_patrimonio_pessoal'] / (df_predicao['renda_total'] + 1)\n",
    "df_predicao['renda_total_log'] = np.log1p(df_predicao['renda_total'])\n",
    "df_predicao['nasceu_onde_reside'] = (df_predicao['estado_onde_nasceu'] == df_predicao['estado_onde_reside']).astype(int)\n",
    "df_predicao['reside_onde_trabalha'] = (df_predicao['estado_onde_reside'] == df_predicao['estado_onde_trabalha']).astype(int)\n",
    "colunas_cartoes = ['possui_cartao_visa', 'possui_cartao_mastercard', 'possui_cartao_diners', 'possui_cartao_amex', 'possui_outros_cartoes']\n",
    "df_predicao['qtde_total_de_cartoes'] = df_predicao[colunas_cartoes].sum(axis=1)\n",
    "\n",
    "# Tratamento de valores extremos\n",
    "df_predicao.loc[df_predicao['qtde_dependentes'] > 10, 'qtde_dependentes'] = 10\n",
    "df_predicao.loc[df_predicao['idade'] < 17, 'idade'] = df_predicao['idade'].median()\n",
    "# df_predicao.loc[df_predicao['meses_no_trabalho'] < 1, 'meses_no_trabalho'] = df_predicao['meses_no_trabalho'].median()\n",
    "\n",
    "colunas_redundantes = [\n",
    "    'renda_mensal_regular', \n",
    "    'renda_extra',\n",
    "    'renda_total',\n",
    "    'valor_patrimonio_pessoal'\n",
    "]\n",
    "\n",
    "df_predicao = df_predicao.drop(columns=colunas_redundantes, errors='ignore')\n",
    "\n",
    "# Tratamento de valores nulos\n",
    "cols_na_subs = ['profissao_companheiro', 'grau_instrucao_companheiro', 'codigo_area_telefone_residencial', 'codigo_area_telefone_trabalho', 'profissao', 'ocupacao']\n",
    "for col in cols_na_subs:\n",
    "    df_predicao[col] = df_predicao[col].fillna(-1)\n",
    "\n",
    "cols_cat_subs = ['estado_onde_trabalha', 'estado_onde_nasceu', 'tipo_residencia'] \n",
    "for col in cols_cat_subs:\n",
    "    moda = df_predicao[col].mode()[0]\n",
    "    df_predicao[col] = df_predicao[col].fillna(moda)\n",
    "\n",
    "cols_num_subs = ['meses_na_residencia'] \n",
    "for col in cols_num_subs:\n",
    "    mediana = df_predicao[col].median()\n",
    "    df_predicao[col] = df_predicao[col].fillna(mediana)\n",
    "\n",
    "df_predicao['sexo'] = df_predicao['sexo'].fillna('N')\n",
    "\n",
    "df_predicao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713306a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41411e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'idade',\n",
    "    'qtde_dependentes',\n",
    "    'meses_na_residencia',\n",
    "    'renda_mensal_regular',\n",
    "    'renda_extra',\n",
    "    'qtde_contas_bancarias',\n",
    "    'qtde_contas_bancarias_especiais',\n",
    "    'valor_patrimonio_pessoal',\n",
    "    'meses_no_trabalho'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    'produto_solicitado',\n",
    "    'dia_vencimento',\n",
    "    'forma_envio_solicitacao',\n",
    "    'tipo_endereco',\n",
    "    'sexo',\n",
    "    'estado_civil',\n",
    "    'grau_instrucao',\n",
    "    'nacionalidade',\n",
    "    'estado_onde_nasceu',\n",
    "    'estado_onde_reside',\n",
    "    'possui_telefone_residencial',\n",
    "    'codigo_area_telefone_residencial',\n",
    "    'tipo_residencia',\n",
    "    'possui_telefone_celular',\n",
    "    'possui_email',\n",
    "    'possui_cartao_visa',\n",
    "    'possui_cartao_mastercard',\n",
    "    'possui_cartao_diners',\n",
    "    'possui_cartao_amex',\n",
    "    'possui_outros_cartoes',\n",
    "    'possui_carro',\n",
    "    'vinculo_formal_com_empresa',\n",
    "    'estado_onde_trabalha',\n",
    "    'possui_telefone_trabalho',\n",
    "    'codigo_area_telefone_trabalho',\n",
    "    'profissao',\n",
    "    'ocupacao',\n",
    "    'profissao_companheiro',\n",
    "    'grau_instrucao_companheiro'\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "scalers = [\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    MaxAbsScaler\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "]\n",
    "\n",
    "imputers = [\n",
    "    SimpleImputer(strategy='mean')\n",
    "]\n",
    "\n",
    "models = {\n",
    "    # 'RandomForest': {\n",
    "    #     'model': RandomForestClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_estimators': [100, 200],\n",
    "    #         'max_depth': [5, 10, None],\n",
    "    #         'min_samples_split': [2, 5, 10]\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy'\n",
    "    # },\n",
    "\n",
    "    # 'SVM': {\n",
    "    #     'model': SVC(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'C': [0.1, 1, 10],\n",
    "    #         'kernel': ['rbf', 'linear'],\n",
    "    #         'gamma': ['scale', 'auto']\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy',\n",
    "    #     'cv': 5\n",
    "    # },\n",
    "\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=2),\n",
    "        'hyperparameters': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 'GradientBoosting': {\n",
    "    #     'model': GradientBoostingClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_estimators': [100, 200],\n",
    "    #         'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #         'max_depth': [3, 5, 7]\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # 'XGBoost': {\n",
    "    #     'model': XGBClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_estimators': [100, 200],\n",
    "    #         'learning_rate': [0.01, 0.1, 0.3],\n",
    "    #         'max_depth': [3, 6, 10]\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # 'AdaBoost': {\n",
    "    #     'model': AdaBoostClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_estimators': [50, 100, 200],\n",
    "    #         'learning_rate': [0.01, 0.1, 1]\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy'\n",
    "    # },\n",
    "\n",
    "    # 'ExtraTrees': {\n",
    "    #     'model': ExtraTreesClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_estimators': [100, 200],\n",
    "    #         'max_depth': [5, 10, None],\n",
    "    #         'min_samples_split': [2, 5, 10]\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy'\n",
    "    # },\n",
    "\n",
    "    # 'KNN': {\n",
    "    #     'model': KNeighborsClassifier(),\n",
    "    #     'hyperparameters': {\n",
    "    #         'n_neighbors': [3, 5, 7],\n",
    "    #         'weights': ['uniform', 'distance'],\n",
    "    #         'metric': ['euclidean', 'manhattan']\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy'\n",
    "    # },\n",
    "\n",
    "    # 'DecisionTree': {\n",
    "    #     'model': DecisionTreeClassifier(random_state=2),\n",
    "    #     'hyperparameters': {\n",
    "    #         'max_depth': [5, 10, None],\n",
    "    #         'min_samples_split': [2, 5, 10],\n",
    "    #         'criterion': ['gini', 'entropy']\n",
    "    #     },\n",
    "    #     'selection_method': 'grid',\n",
    "    #     'scoring': 'accuracy'\n",
    "    # }\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
